{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9849708,"sourceType":"datasetVersion","datasetId":6043662}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nimport matplotlib.pyplot as plt\nimport datetime\nimport os\nimport gc\n\n# Check for GPU availability\nif tf.config.list_physical_devices('GPU'):\n    strategy = tf.distribute.MirroredStrategy()  # Multi-GPU setup if available\nelse:\n    strategy = tf.distribute.get_strategy()  # Fallback to CPU strategy\n\nprint('Number of devices:', strategy.num_replicas_in_sync)\n\ntrain_dir = '/kaggle/input/accident-detection-main/Vision_balance_Resize_Update/Train'\ntest_dir = '/kaggle/input/accident-detection-main/Vision_balance_Resize_Update/Test'\n\ntarget_size = (224, 224)\nbatch_size = 4  # Adjust as needed based on GPU memory\n\n# Enable mixed precision if supported\ntry:\n    from tensorflow.keras.mixed_precision import set_global_policy\n    set_global_policy('mixed_float16')\nexcept ImportError:\n    pass\n\nlog_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\nos.makedirs(log_dir, exist_ok=True)\n\nclass CustomLoggingCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        print(f\"\\nEpoch {epoch + 1} - loss: {logs['loss']:.4f} - accuracy: {logs['accuracy']:.4f} - val_loss: {logs['val_loss']:.4f} - val_accuracy: {logs['val_accuracy']:.4f}\")\n\n# ClearMemoryCallback to release memory after each epoch\nclass ClearMemoryCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        tf.keras.backend.clear_session()\n        gc.collect()\n        print(f\"Cleared memory after epoch {epoch + 1}\")\n\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, target_size)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    return image, label\n\ndef get_dataset(directory, subset):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        directory,\n        labels='inferred',\n        label_mode='binary',\n        batch_size=batch_size,\n        image_size=target_size,\n        validation_split=0.2,\n        subset=subset,\n        seed=123\n    )\n    dataset = dataset.map(preprocess_image).shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_dataset = get_dataset(train_dir, 'training')\nval_dataset = get_dataset(train_dir, 'validation')\n\nwith strategy.scope():\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*target_size, 3))\n    for layer in base_model.layers[:-20]:\n        layer.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(32, activation='relu')(x)\n    output = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    optimizer = Adam(learning_rate=1e-4, clipnorm=1.0)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min', save_freq='epoch')\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n    custom_logger = CustomLoggingCallback()\n\n    # Adding ClearMemoryCallback to callbacks list\n    history = model.fit(\n        train_dataset,\n        epochs=50,\n        validation_data=val_dataset,\n        callbacks=[early_stopping, model_checkpoint, reduce_lr, tensorboard_callback, custom_logger, ClearMemoryCallback()]\n    )\n\ntf.keras.backend.clear_session()\n\ntest_dataset = get_dataset(test_dir, 'validation')\ntest_loss, test_accuracy = model.evaluate(test_dataset)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n\ndef plot_metrics(history):\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Val Loss')\n    plt.title('Loss over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n    plt.title('Accuracy over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\nplot_metrics(history)\n\nprint(f\"\\nTo monitor the training in real-time, use the following command to launch TensorBoard:\")\nprint(f\"!tensorboard --logdir={log_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:53.642505Z","iopub.execute_input":"2024-11-09T11:02:53.642885Z","iopub.status.idle":"2024-11-09T14:33:45.357649Z","shell.execute_reply.started":"2024-11-09T11:02:53.642851Z","shell.execute_reply":"2024-11-09T14:33:45.356356Z"}},"outputs":[{"name":"stdout","text":"Number of devices: 1\nFound 189545 files belonging to 2 classes.\nUsing 151636 files for training.\nFound 189545 files belonging to 2 classes.\nUsing 37909 files for validation.\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 11:07:54.892716: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37908/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7412 - loss: 0.5190\nEpoch 1 - loss: 0.4401 - accuracy: 0.8031 - val_loss: 0.3645 - val_accuracy: 0.9062\nCleared memory after epoch 1\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1579s\u001b[0m 41ms/step - accuracy: 0.7412 - loss: 0.5190 - val_accuracy: 0.9062 - val_loss: 0.3645 - learning_rate: 1.0000e-04\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 11:33:59.605155: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8772 - loss: 0.3181\nEpoch 2 - loss: 0.2997 - accuracy: 0.8869 - val_loss: 0.3296 - val_accuracy: 0.9300\nCleared memory after epoch 2\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1550s\u001b[0m 41ms/step - accuracy: 0.8772 - loss: 0.3181 - val_accuracy: 0.9300 - val_loss: 0.3296 - learning_rate: 1.0000e-04\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 11:59:48.911371: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9080 - loss: 0.2567\nEpoch 3 - loss: 0.2458 - accuracy: 0.9133 - val_loss: 0.2844 - val_accuracy: 0.9476\nCleared memory after epoch 3\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1537s\u001b[0m 40ms/step - accuracy: 0.9080 - loss: 0.2567 - val_accuracy: 0.9476 - val_loss: 0.2844 - learning_rate: 1.0000e-04\nEpoch 4/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 12:25:25.631633: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9251 - loss: 0.2227\nEpoch 4 - loss: 0.2116 - accuracy: 0.9287 - val_loss: 0.3423 - val_accuracy: 0.9488\nCleared memory after epoch 4\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1544s\u001b[0m 41ms/step - accuracy: 0.9251 - loss: 0.2227 - val_accuracy: 0.9488 - val_loss: 0.3423 - learning_rate: 1.0000e-04\nEpoch 5/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 12:51:09.726114: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9372 - loss: 0.1956\nEpoch 5 - loss: 0.1895 - accuracy: 0.9391 - val_loss: 0.3670 - val_accuracy: 0.9525\nCleared memory after epoch 5\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1539s\u001b[0m 40ms/step - accuracy: 0.9372 - loss: 0.1956 - val_accuracy: 0.9525 - val_loss: 0.3670 - learning_rate: 1.0000e-04\nEpoch 6/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 13:16:48.319623: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37908/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9435 - loss: 0.1807\nEpoch 6 - loss: 0.1727 - accuracy: 0.9456 - val_loss: 0.3384 - val_accuracy: 0.9557\nCleared memory after epoch 6\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1533s\u001b[0m 40ms/step - accuracy: 0.9435 - loss: 0.1807 - val_accuracy: 0.9557 - val_loss: 0.3384 - learning_rate: 1.0000e-04\nEpoch 7/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 13:42:20.926820: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9546 - loss: 0.1478\nEpoch 7 - loss: 0.1407 - accuracy: 0.9569 - val_loss: 0.3462 - val_accuracy: 0.9614\nCleared memory after epoch 7\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1541s\u001b[0m 40ms/step - accuracy: 0.9546 - loss: 0.1478 - val_accuracy: 0.9614 - val_loss: 0.3462 - learning_rate: 5.0000e-05\nEpoch 8/50\n","output_type":"stream"},{"name":"stderr","text":"2024-11-09 14:08:01.711071: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9595 - loss: 0.1344\nEpoch 8 - loss: 0.1292 - accuracy: 0.9609 - val_loss: 0.3976 - val_accuracy: 0.9582\nCleared memory after epoch 8\n\u001b[1m37909/37909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1544s\u001b[0m 41ms/step - accuracy: 0.9595 - loss: 0.1344 - val_accuracy: 0.9582 - val_loss: 0.3976 - learning_rate: 5.0000e-05\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m get_dataset(train_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m get_dataset(train_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m     70\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m EfficientNetB0(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m*\u001b[39mtarget_size, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:819\u001b[0m, in \u001b[0;36m_CurrentDistributionContext.__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    814\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    815\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable scope nesting error: move call to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.distribute.set_strategy() out of `with` scope.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    818\u001b[0m         e)\n\u001b[0;32m--> 819\u001b[0m \u001b[43m_pop_per_thread_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:371\u001b[0m, in \u001b[0;36m_pop_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pop_per_thread_mode\u001b[39m():\n\u001b[0;32m--> 371\u001b[0m   \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: pop from empty list"],"ename":"IndexError","evalue":"pop from empty list","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n# Test directory\ntest_dir = '/kaggle/input/accident-detection-main/Vision_balance_Resize_Update/Test'\ntarget_size = (224, 224)\nbatch_size = 4\n\n# Define the strategy\nif tf.config.list_physical_devices('GPU'):\n    strategy = tf.distribute.MirroredStrategy()\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# Load model and weights\nwith strategy.scope():\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    for layer in base_model.layers[:-20]:\n        layer.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(32, activation='relu')(x)\n    output = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    optimizer = Adam(learning_rate=1e-4, clipnorm=1.0)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Load the saved weights from training\nmodel.load_weights('best_model.keras')\n\n# Prepare the test dataset\ntest_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    test_dir,\n    labels='inferred',\n    label_mode='binary',\n    batch_size=batch_size,\n    image_size=target_size,\n    shuffle=False\n)\n\n# Evaluate the model on the test dataset\ntest_loss, test_accuracy = model.evaluate(test_dataset)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T14:41:50.926170Z","iopub.execute_input":"2024-11-09T14:41:50.926550Z","iopub.status.idle":"2024-11-09T14:43:20.701714Z","shell.execute_reply.started":"2024-11-09T14:41:50.926515Z","shell.execute_reply":"2024-11-09T14:43:20.700760Z"}},"outputs":[{"name":"stdout","text":"Found 21918 files belonging to 2 classes.\n\u001b[1m5480/5480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 14ms/step - accuracy: 0.4751 - loss: 3.6019\nTest Loss: 1.8700186014175415, Test Accuracy: 0.6905739307403564\n","output_type":"stream"}],"execution_count":3}]}